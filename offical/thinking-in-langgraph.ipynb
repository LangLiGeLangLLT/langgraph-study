{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0263dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen3-max-2026-01-23\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1b1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "\n",
    "# Define the structure for email classification\n",
    "class EmailClassification(TypedDict):\n",
    "    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "    topic: str\n",
    "    summary: str\n",
    "\n",
    "\n",
    "class EmailAgentState(TypedDict):\n",
    "    # Raw email data\n",
    "    email_content: str\n",
    "    sender_email: str\n",
    "    email_id: str\n",
    "\n",
    "    # Classification result\n",
    "    classification: EmailClassification | None\n",
    "\n",
    "    # Raw search/API results\n",
    "    search_results: list[str] | None  # List of raw document chunks\n",
    "    customer_history: dict | None  # Raw customer data from CRM\n",
    "\n",
    "    # Generated content\n",
    "    draft_response: str | None\n",
    "    messages: list[str] | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bcca1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt, Command, RetryPolicy\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "\n",
    "def read_email(state: EmailAgentState) -> EmailAgentState:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=f\"Processing email: {state['email_content']}\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def classify_intent(\n",
    "    state: EmailAgentState,\n",
    ") -> Command[\n",
    "    Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]\n",
    "]:\n",
    "    structured_llm = llm.with_structured_output(EmailClassification)\n",
    "\n",
    "    classification_prompt = f\"\"\"\n",
    "    Analyze this customer email and classify it:\n",
    "\n",
    "    Email: {state['email_content']}\n",
    "    From: {state['sender_email']}\n",
    "\n",
    "    Provide classification including intent, urgency, topic, and summary.\n",
    "    \"\"\"\n",
    "\n",
    "    classification = structured_llm.invoke(classification_prompt)\n",
    "\n",
    "    if classification[\"intent\"] == \"billing\" or classification[\"urgency\"] == \"critical\":\n",
    "        goto = \"human_review\"\n",
    "    elif classification[\"intent\"] in [\"question\", \"feature\"]:\n",
    "        goto = \"search_documentation\"\n",
    "    elif classification[\"intent\"] == \"bug\":\n",
    "        goto = \"bug_tracking\"\n",
    "    else:\n",
    "        goto = \"draft_response\"\n",
    "\n",
    "    return Command(update={\"classification\": classification}, goto=goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4911d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documentation(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    classification = state.get(\"classification\", {})\n",
    "    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n",
    "\n",
    "    try:\n",
    "        search_results = [\n",
    "            \"Reset password via Settings > Security > Change Password\",\n",
    "            \"Password must be at least 12 characters\",\n",
    "            \"Include uppercase, lowercase, numbers, and symbols\",\n",
    "        ]\n",
    "    except:\n",
    "        search_results = [f\"Search temporarily unavailable\"]\n",
    "\n",
    "    return Command(update={\"search_results\": search_results}, goto=\"draft_response\")\n",
    "\n",
    "\n",
    "def bug_tracking(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    ticket_id = \"BUG-12345\"\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"search_results\": [f\"Bug ticket {ticket_id} created\"],\n",
    "            \"current_step\": \"bug_tracked\",\n",
    "        },\n",
    "        goto=\"draft_response\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14775707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_response(\n",
    "    state: EmailAgentState,\n",
    ") -> Command[Literal[\"human_review\", \"send_reply\"]]:\n",
    "    \"\"\"Generate response using context and route based on quality\"\"\"\n",
    "\n",
    "    classification = state.get(\"classification\", {})\n",
    "\n",
    "    # Format context from raw state data on-demand\n",
    "    context_sections = []\n",
    "\n",
    "    if state.get(\"search_results\"):\n",
    "        # Format search results for the prompt\n",
    "        formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state[\"search_results\"]])\n",
    "        context_sections.append(f\"Relevant documentation:\\n{formatted_docs}\")\n",
    "\n",
    "    if state.get(\"customer_history\"):\n",
    "        # Format customer data for the prompt\n",
    "        context_sections.append(\n",
    "            f\"Customer tier: {state['customer_history'].get('tier', 'standard')}\"\n",
    "        )\n",
    "\n",
    "    # Build the prompt with formatted context\n",
    "    draft_prompt = f\"\"\"\n",
    "    Draft a response to this customer email:\n",
    "    {state['email_content']}\n",
    "\n",
    "    Email intent: {classification.get('intent', 'unknown')}\n",
    "    Urgency level: {classification.get('urgency', 'medium')}\n",
    "\n",
    "    {chr(10).join(context_sections)}\n",
    "\n",
    "    Guidelines:\n",
    "    - Be professional and helpful\n",
    "    - Address their specific concern\n",
    "    - Use the provided documentation when relevant\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(draft_prompt)\n",
    "\n",
    "    # Determine if human review needed based on urgency and intent\n",
    "    needs_review = (\n",
    "        classification.get(\"urgency\") in [\"high\", \"critical\"]\n",
    "        or classification.get(\"intent\") == \"complex\"\n",
    "    )\n",
    "\n",
    "    # Route to appropriate next node\n",
    "    goto = \"human_review\" if needs_review else \"send_reply\"\n",
    "\n",
    "    return Command(\n",
    "        update={\"draft_response\": response.content},  # Store only the raw response\n",
    "        goto=goto,\n",
    "    )\n",
    "\n",
    "\n",
    "def human_review(state: EmailAgentState) -> Command[Literal[\"send_reply\", END]]:\n",
    "    \"\"\"Pause for human review using interrupt and route based on decision\"\"\"\n",
    "\n",
    "    classification = state.get(\"classification\", {})\n",
    "\n",
    "    # interrupt() must come first - any code before it will re-run on resume\n",
    "    human_decision = interrupt(\n",
    "        {\n",
    "            \"email_id\": state.get(\"email_id\", \"\"),\n",
    "            \"original_email\": state.get(\"email_content\", \"\"),\n",
    "            \"draft_response\": state.get(\"draft_response\", \"\"),\n",
    "            \"urgency\": classification.get(\"urgency\"),\n",
    "            \"intent\": classification.get(\"intent\"),\n",
    "            \"action\": \"Please review and approve/edit this response\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Now process the human's decision\n",
    "    if human_decision.get(\"approved\"):\n",
    "        return Command(\n",
    "            update={\n",
    "                \"draft_response\": human_decision.get(\n",
    "                    \"edited_response\", state.get(\"draft_response\", \"\")\n",
    "                )\n",
    "            },\n",
    "            goto=\"send_reply\",\n",
    "        )\n",
    "    else:\n",
    "        # Rejection means human will handle directly\n",
    "        return Command(update={}, goto=END)\n",
    "\n",
    "\n",
    "def send_reply(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Send the email response\"\"\"\n",
    "    # Integrate with email service\n",
    "    print(f\"Sending reply: {state['draft_response'][:100]}...\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598e8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import RetryPolicy\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(EmailAgentState)\n",
    "\n",
    "# Add nodes with appropriate error handling\n",
    "workflow.add_node(\"read_email\", read_email)\n",
    "workflow.add_node(\"classify_intent\", classify_intent)\n",
    "\n",
    "# Add retry policy for nodes that might have transient failures\n",
    "workflow.add_node(\n",
    "    \"search_documentation\",\n",
    "    search_documentation,\n",
    "    retry_policy=RetryPolicy(max_attempts=3)\n",
    ")\n",
    "workflow.add_node(\"bug_tracking\", bug_tracking)\n",
    "workflow.add_node(\"draft_response\", draft_response)\n",
    "workflow.add_node(\"human_review\", human_review)\n",
    "workflow.add_node(\"send_reply\", send_reply)\n",
    "\n",
    "# Add only the essential edges\n",
    "workflow.add_edge(START, \"read_email\")\n",
    "workflow.add_edge(\"read_email\", \"classify_intent\")\n",
    "workflow.add_edge(\"send_reply\", END)\n",
    "\n",
    "# Compile with checkpointer for persistence, in case run graph with Local_Server --> Please compile without checkpointer\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c71f13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human review interrupt:[Interrupt(value={'email_id': 'email_123', 'original_email': 'I was charged twice for my subscription! This is urgent!', 'draft_response': '', 'urgency': 'critical', 'intent': 'billing', 'action': 'Please review and approve/edit this response'}, id='885219dfb295d069092aa0a461d6beff')]\n",
      "Sending reply: We sincerely apologize for the double charge. I've initiated an immediate refund......\n",
      "Email sent successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test with an urgent billing issue\n",
    "initial_state = {\n",
    "    \"email_content\": \"I was charged twice for my subscription! This is urgent!\",\n",
    "    \"sender_email\": \"customer@example.com\",\n",
    "    \"email_id\": \"email_123\",\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "# Run with a thread_id for persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"customer_123\"}}\n",
    "result = app.invoke(initial_state, config)\n",
    "# The graph will pause at human_review\n",
    "print(f\"human review interrupt:{result['__interrupt__']}\")\n",
    "\n",
    "# When ready, provide human input to resume\n",
    "from langgraph.types import Command\n",
    "\n",
    "human_response = Command(\n",
    "    resume={\n",
    "        \"approved\": True,\n",
    "        \"edited_response\": \"We sincerely apologize for the double charge. I've initiated an immediate refund...\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Resume execution\n",
    "final_result = app.invoke(human_response, config)\n",
    "print(f\"Email sent successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
